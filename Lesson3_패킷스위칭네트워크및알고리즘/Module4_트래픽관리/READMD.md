# 1. 패킷 수준 - 스케쥴링 및 QoS
***
- 트래픽 관리는 최종 사용자에게 서비스 품질을 제공하고 네트워크 리소스를 효율적으로 사용하는 것과 관련이 있음
- 트래픽 관리는 3가지 수준으로 분류
  - Packet
  - Flow
  - Flow-Aggregate
### Time Scales & Granularities
- 패킷 수준에서 트래픽 관리는 주로 스위치, 라우터 및 멀티플렉서의 패킷 큐잉 및 패킷 스케쥴링과 관련
- 서로 다른 서비스 품질 클래스에 속하는 패킷에 대해 차별화된 처리를 제공함
- 흐름 수준에서 사용자에게 제공되는 서비스의 품질을 보장하기 위해 개별 트래픽 흐름을 관리하는데 중점을 둠
- 플로우 애그리거트 (Flow-Aggregate) 수준에서는 네트워크를 통해 집계된 트래픽 흐름을 서로 다른 수준으로 라우팅, 시간 규모도 다름
### End-to-End QoS
- 경로는 패킷을 통과하므로 네트워크를 일련의 대기열 시스템으로 모델링 가능
- 패킷 트래버싱 네트워크에서는 다양한 멀티플렉싱 지점에서 지연이 발생하고 손실이 발생할 수 있음
- 다른 플로우의 패킷이 경로를 따라 버퍼 및 전송 용량을 포함하는 패킷을 방해할 수 있음
- end-to-end 성능은 per-hop 성능의 누적임
- 각 시스템의 지연을 일부 업바운드 미만으로 유지할 수 있다면, end-to-end 지연은 업바운드 합계 이하로 유지할 수 있음
- 패킷 손실은 수신 패킷에 사용할 수 있는 버퍼가 더 이상 없을 때 발생함
- 모든 패킷 손실은 패킷 도착 시 버퍼링을 검색하며 패킷 수가 적거나 다운스트림 혼잡으로 인해 전송 시간이 늘어남
### Scheduling & QoS
- 패킷 스위치 네트워크는 다양한 서비스 품질 요구 사항과 함께 광범위한 서비스를 지원해야 함
- 대기열 시스템은 정보 흐름에 제공되는 전송 비트레이트를 제어하는 전략을 구현해야 함 - 대기열 스케쥴링
- 스케쥴링에서 고려되는 요소
  - 공정성
  - 우선 순위
  - 격리성
- 버퍼 관리는 패킷이 시스템에 배치되는 방식을 관리하는 데 필요
### FIFO Queueing
- 선입선출 대기열
- 모든 패킷 흐름은 동일한 버퍼를 공유하고 패킷은 도착 순서대로 전송됨
- 버퍼가 가득 차면 도착하는 패킷을 폐기
- 패킷이 겪는 지연 및 손실은 패킷 간 도착 시간과 패킷 길이에 따라 달라짐
- 다양한 패킷 흐름에 차등적인 서비스 품질을 제공할 수 없음
- 한 세션에서 사용자가 더 높은 속도로 패킷을 전송하고 버퍼를 채워 다른 사용자가 해당 버퍼에 액세스 할 수 없게 되면 호깅 발생
- 유한 버퍼는 가능한 최대 지연을 결정함
- 크기 또한 손실 확률에 영향을 미침
### FIFO w/o and w/Discard Priority
- FIFO 큐 관리를 수정하여 다양한 트래픽 클래스에 서로 다른 패킷 특성과 손실 성능을 제공할 수 있음
- 버퍼의 패킷 수가 특정 임계값에 도달하면 액세스 우선 순위가 낮은 패킷이 시스템에 도착할 수 없음
- 즉, 임계값을 초과하면 우선순위 비용이 더 많이 들지만 패킷은 폐기됨
- 버퍼가 가득 차지 않는 한 패킷은 허용됨
- 액세스 품질이 낮은 패킷은 패킷 손실 가능성이 높아지므로 성능 차별화가 제공됨
### HOL Priority Queueing
- HOL(Head of Line) 우선순위 큐잉은 여러 우선 순위 클래스를 정의하는 또 다른 접근 방식
- 각 우선순위 클래스마다 별도의 버퍼가 유지됨
- 우선 순위가 가장 높고 비어있지 않은 대기열의 HOL 중에서 선택됨
- 우선 순위가 높은 대기열은 대기 시간이 더 짧음
- 다양한 손실 확률에 맞게 버퍼 크기를 지정가능
### 요약
- HOL 우선순위 큐잉은 차별화된 서비스 품질 제공가능
- 하지만 우선순위가 낮은 클래스에 전송 대역폭에 대한 액세스를 어느정도 보장할 수 없다는 단점이 있음
- 우선 순위가 높은 대기열이 급증하면 우선 순위가 낮은 대기열이 포화 상태가 될 수 있음
- 따라서 특정 클래스를 어느 정도 격리하려면 우선 순위가 우선적으로 필요하지 않음
***
# 2. 패킷 수준 - Fair Queuing, RED
***
### Fair Queuing
- 전송 대역폭에 대해 격리되고 공평한 액세슬르 제공하기 위한 것
- 각 사용자 흐름에는 고유한 논리적 버퍼가 있음
- 이상적인 시스템에서는 패킷이 있는 버퍼에 전송 대역폭이 균등하게 분배됨
- 프로세서 공유라고도 함
- Weighted fair queueing (WFQ) 가중치 기반 페어 큐잉은 우선순위가 다른 여러 사용자에 대해 문제를 해결함
- 공정한 대기열에 초점
### Fair Queuing - Fluid
- 전송이 자유로운 이상적인 상황에서는 전송 대역폭이 비어 있지 않은 모든 버퍼에 균등하게 분배됨
- 비어 있지 않은 각 버퍼를 라운드로빈 방식으로 한번에 한비트씩 서비스하는 것도 한가지 방법
- 시스템의 총 흐름 수가 n개이고 전체 전송 용량이 C인 경우 각 흐름은 초당 n비트에 대해 C 이상 보장되어야 함
### Fair Queuing - Approximation
- 실제로 전송 용량을 정확히 동일하게 나누는 것은 기술적으로 불가능함
- 비트별 라운드 로빈 서비스를 사용하려면 결과 비트 스트림을 구성 요소 네트워크로 분해해야 하므로 엄청난 비용이 듬
- ATM의 경우 공정한 큐잉을 보다 쉽게 파악할 수 있음
- ATM에서는 모드 패킷의 길이가 같기 때문
- 패킷 네트워크에서 공정한 대기열을 구현하려면 근사치가 필요
### 예제 참고
- 실제 수만개의 흐름이 존재할 수 있는 네트워크에서는 거의 구현되지 않음
- 구현 오버헤드가 크게 증가하고 시스템을 확장할 수 없기 때문
### Buffer Management
- 버퍼 관리에는 패킷 삭제 전략이 포함
- 라우터의 버퍼가 가득 찼을 때 어떤 패킷을 삭제하는가?
- 공정성이 중요한 요구사항인 경우 라우터는 잘못된 소스로부터 작동하는 소스를 보호해야 합니다
- 집계 수준이 다르면 다양한 보호 기능이 제공됨
- flow-aggregation 버퍼는 잘못된 플로우로부터 플로우를 보호함
- 반면 full aggregation 버퍼는 보호 기능을 제공하지 않음
- 클래스로의 aggregation은 중간 수준의 보호를 제공
- 버퍼는 다른 작업 우선 순위를 구현할 수 있으므로 다른 클래스에 속하는 패킷은 우선 순위에 따라 삭제될 수 있음
- 우선 순위 삭제를 통해 특정 애플리케이션의 서비스 품질을 출족하면서 네트워크 활용도를 극대화할 수 있음
- 네트워크 엣지의 소스가 협력할 수 있다면 네트워크 코어의 버퍼 관리가 더 효율적일 수 있음
- 버퍼가 특정 수준에 도달하기 시작하면 소스에 알림을 보내 패킷을 보내는 속도를 줄임
### Random Early Detection (RED)
- RED는 대기열 길이가 지정된 임계값을 초과할 경우 패킷을 삭제하는 버퍼 관리 기법임
- 패킷 삭제 가능성은 대기열 길이에 따라 선형적으로 증가함
- 삭제된 패킷은 소스 측에 피드백 정보를 누락 확인으로 제공하므로 전송률을 암시적으로 낮추도록 소스에 알림
- 특정 소스가 다른 소스보다 높은 속도로 전송하는 경우 해당 소스는 더 높은 패킷 손실률로 어려움을 겪음
### Packet Drop Profile in RED
- TCP 프로토콜에서 패킷 생산자는 네트워크 혼잡에 대응하여 입력 속도를 줄임
- 랜덤 드롭으로 인해 일부 소스가 다른 소스보다 먼저 속도를 낮추게 되어 총 입력 속도가 점진적으로 감소함
- 협력하는 TCP 소스의 성능을 향상시키고 TCP 소스의 손실 확률이나 오작동 가능성을 높임
- 기술적으로 RED는 대기열 길이의 실행 평균을 유지함
- 최소 임계값과 최대 임계값 정의
- 평균 대기열 길이가 최소 임계값 미만인 경우 RED는 도착하는 패킷을 삭제하지 않음
- 평균 대기열 길이가 최소 임계값과 최대 임계값 사이인 경우 RED는 도착 패킷을 삭제하며 평균 대기열 길이가 길어질수록 확률이 증가함
- 초기 방식은 버퍼가 가득 차기 전에 전송 속도를 낮추도록 일부 소스에 알리는데 사용됨
- 평균 대기열 길이가 최대 임계값을 초과하면 RED는 도착하는 모든 패킷을 삭제함
***
# 3. 플로우 수준 - 누수 버킷 폴리싱
***
### Why Congestion?
- 트래픽이 급증하면 전송 및 버퍼링 시 네트워크 리소스가 과부하될 때 발생함
- 패킷 스위칭 네트워크의 예
- 노드1,2,5가 노드4를 통해 목적지로 지속적으로 패킷 전송 가정
- 노드 4로 이동하는 패킷의 총 수신 속도가 전송용량보다 크면 노드 4의 버퍼가 쌓여 결국 패킷 폐기를 시작함
- 프로토콜에 누락된 패킷에 대한 실제 전송이 필요한 경우 혼잡은 더욱 심해짐
### Ideal Effect of Congestion Control
- 흐름 수준에서 트래픽을 관리하는 목적은 트래픽 혼잡이 있는 상황에서도 트래픽 흐름을 제어하고 성능을 유지하는 것
- 이 프로세스를 혼잡 제어라고 하며, ppt의 그래프와 같은 바람직한 성능을 달성하는 것을 목표로 함
- 혼잡 제어는 패킷 라우팅과 마찬가지로 매우 어려운 문제
- 접근 방식에는 크게 2가지 범주
  - 예방 접근법
    - 일정 및 리소스 예약에 기반한 오픈 루프 방식
  - 사후 대응적 접근 방식
    - 폐기에 기반한 폐쇄형 루프 방식
### Open-Loop Control
- 개방형 루프 제어
- 혼잡에 대응할 때 피드백 정보에 의존하지 않음
- 대신 허용된 흐름의 수명동안 네트워크 성능을 보장하는 것을 목표로 함
- 주요 메커니즘
  - 승인 제어
  - Policing
  - 트래픽 쉐이핑
### Admission Control
- 승인 제어는 연결 지향 가상 회로 패킷 네트워크를 위해 개발됨
- 플로우는 네트워크와 계약을 협상하여 피크, 최대 버스트 크기, 지연 및 손실에 대한 요구 사항을 지정함
- 최대 버스트 크기에 따라 트래픽이 생성될 수 있는 최대 시간 및 최대 속도가 결정됨
- 네트워크가 리소스를 계산함
- 일반적으로 새 흐름의 대역폭 및 버퍼링 요구 사항은 리소스가 사용 가능한 흐름을 따라갈 경로를 따르는지 여부를 결정함
### Policing
- 소스가 계약을 위반하는 것을 방지하기 위해 네트워크는 트래픽 흐름을 지속적으로 모니터링하여 트래픽 계약을 준수하는지 확인함
- 패킷이 계약을 위반하는 경우 네트워크는 우선 순위가 낮은 패킷을 폐기하거나 태그를 지정할 수 있음
- 혼잡이 발생하면 태그가 지정된 패킷이 먼저 삭제됨
- 트래픽 흐름을 모니터링하고 적용하는 프로세스를 폴리싱이라고 함
### Leaky Bucket Illustration
- 대부분의 폴리싱 장치 구현은 누수 버킷의 개념을 기반으로 함
- 물이 새는 버킷의 경우 누수율이 지정되어 있음
- 버킷에는 도착률의 변동에 맞게 깊이가 지정되어 있음
- 도착하는 패킷이 오버플로를 초래하지 않는다면 정상 작동한 것
- 네트워크 시나리오에서 드레인은 유동적인 것이 아니라 패킷당 발생한다는 점에 유의
### Leaky Bucket in ATM Network
- ATM에서 발생하는 Leaky Bucket
- 모든 패킷의 고정 길이는 동일함
- 카운터는 leaky bucket의 내용을 기록함
- 패킷이 도착하면 버킷이 한도를 초과하지 않는 경우 카운터는 I만큼 증가함
- 이 경우 패킷이 규정을 준수하는 것이 더 명확함
- 값 I는 폴리싱되는 패킷의 평균 inter-arrival 시간을 나타냄
### Leaky Bucket Example
- L은 일반적으로 트래픽에 따라 달라짐
- 그림의 상단은 다른 시간에 도착한 패킷을 보여줌
- 그림의 하단은 버킷 콘텐츠 측면에서 누수 버킷의 동작을 보여줌
- 시간 t2에 첫 번째 패킷이 들어와 버킷에 저장됨
- 버킷의 깊이는 I만큼 즉시 증가함.
- 한 단위 시간 후, 유닛 또는 패킷이 전송되어 버킷의 깊이가 3이 될 때, 패킷이 계속 다른 시간에 전송됨에 따라 버킷 내용도 계속 변경됨
- 첫 번째 Nonconforming 패킷은 t5에 도착하는 패킷 5
- 이 때 버킷 콘텐츠는 7이 되어 비컷에 패킷 5를 추가함. 버킷이 오버플로될 수 있음
- t7에서는 모든 패킷이 소진되므로 버킷은 비어 있음
***
# 4. 토큰 버킷별 트래픽 형성
***
### Flow-level Traffic Shaping
- 소스 노드에서 트래픽 흐름이 누수 버킷 폴리싱 디바이스에 지정된 매개변수를 준수하도록 하려면 트래픽 흐름을 변경해야 할 수 있음
- 트래픽 쉐이핑은 규정 준수를 보장하기 위해 트래픽 흐름을 변경하는 프로세스를 의미함
- 트래픽 쉐이핑 디바이스는 트래픽 흐름이 네트워크를 떠나기 직전에 노드에 위치하는 경우가 많음
- 트래픽 폴리싱 장치는 일반적으로 네트워크로부터 트래픽 흐름을 수신한 노드에 있음
### Leaky Bucket Traffic Shaper
- 누수 버킷 트래픽 쉐이퍼에서는 들어오는 패킷이 먼저 버퍼에 저장됨
- 패킷은 주기적으로 제공되므로 패킷 스트림, 즉 출력은 평활화되고 버퍼는 일시적인 패킷 버스트를 저장하는데 사용됨
- 그 크기에 따라 수용할 수 있는 최대 버스트가 결정됨
- 너무 제한적이어서 가변 속도의 발신 트래픽을 허용하지 않을 수도 있다는 점
### Token Bucket Traffic Shaper
- 좀 더 현실적인 쉐이퍼인 토큰 버킷 트래픽 쉐이퍼
- 규정을 준수하지 않는 것은 패킷뿐 - 누수 버킷의 연장선
- 토큰은 일정한 속도로 주기적으로 생성되며 토큰 버킷에 저장됨
- 토큰 버킷이 가득 차면 도착한 토큰은 폐기됨
- 버킷의 토큰을 인출할 수 있는 경우에만 버퍼에서 패킷을 전송할 수 있음
- 토큰 버킷이 비어 있는 경우 도착하는 패킷은 패킷 버퍼에서 대기해야 함
- 토큰은 패킷 전송을 위한 허가라고 볼 수 있음
- 토큰 패킷의 크기는 전송될 수 있는 burstiness의 양을 의미함
### Token Bucket Shaping Effect (full & empty)
- 버퍼에 백로그된 패킷이 있지만 토큰 버킷이 비어 있는 경우 토큰 버킷 쉐이핑 효과는 어떻게 될것인가?
- 백로그된 패킷은 새 토큰이 생성될 때까지 기다려야 전송될 수 있음
- 토큰은 주기적으로 도착함
- 패킷은 토큰이 도착하는 속도로 주기적으로 전송됨
- 토큰 버킷 쉐이퍼의 동작은 누수 버킷 쉐이퍼의 동작과 매우 유사함
- 토큰 버킷의 크기는 근본적으로 트래픽 폭주 및 출력을 제한함
- 버킷 크기가 0으로 줄어들면 토큰 버킷 쉐이퍼는 누수 버킷 쉐이퍼가 됨
### Closed-Loop Flow Control
- 혼잡제어
  - 일반적으로 피드백 정보에 의존하는 폐쇄형 루프 제어 메커니즘을 통해 해결됨
  - 네트워크에 대한 피드백 정보에 따라 패킷 흐름 속도를 조절함
  - 피드백 정보에는 버퍼 길이, 링크 사용률 등이 포함됨
  - 피드백 정보의 수신자는 일반적으로 혼잡 제어를 담당하는 통신계층에 따라 달라짐
  - 예를 들어, TCP 프로토콜에서는 전달 계층에서 제어가 구현됨
  - 네트워크 상태의 수신자는 소스 노드에 있음
- 구현 방식
  - 종단 간 제어
  - hop-by-hop
  - 암시적 피드백
  - 명시적 피드백
### E2E vs H2H Congestion Control
- 종단 간 폐쇄 루프 제어를 사용하면 정보 피드백이 소스 노드로 다시 전파되어 소스 노드가 패킷 흐름속도를 조절할 수 있음
- TCP는 이 접근 방식을 취함
- 단점은 정보를 수신할 때 정보가 정확하지 않을 수 있다는 것
- 홉별 제어는 일반적으로 셔터 전파 지연으로 인해 훨씬 빠르게 반응할 수 있음
### Congestion Warning
- 피드백 정보는 암시적일 수 있고 명시적일 수도 있음
- 암시적 피드백은 혼잡 경고 알림 비트일수 있고 혼잡을 경고하는 특수 choke 패킷일 수 있음
- 승인 누락으로 인한 시간 초과일 수 있음
### Aggregate Level - Traffic Engineering
- 흐름 집계 수준에서 트래픽 관리는 많은 흐름을 처리함
- 리소스를 효율적으로 활용하고 서비스 수준을 충족하기 위해 네트워크를 통해 총 트래픽 흐름을 라우팅하는 것을 목표로 함
- 이러한 수준의 관리를 일반적으로 트래픽 엔지니어링이라고 하며 몇 분에서 며칠 단위로 수행됨